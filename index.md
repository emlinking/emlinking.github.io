---
layout: default
title: Eleanor M. Lin
---
<link rel="stylesheet" href="css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="css/style.css">

<br />
<br />
<img src="images/IMG_0382.JPG" width="200"/>
 
<h3 id="name" class="p-0 m-0 mb-1">Eleanor M. Lin</h3>

B. A. Candidate, Computer Science and Linguistics  
[Department of Computer Science](https://www.cs.columbia.edu/) and [Program of Linguistics](https://slavic.columbia.edu/content/linguistics)  
Columbia University  
e.lin2@columbia.edu

I am a senior double-majoring in linguistics and computer science at Columbia University. At Columbia's [Speech Lab](http://www.cs.columbia.edu/speech/index.cgi), I currently research code-switching, under the mentorship of Professor [Julia Hirschberg](http://www.cs.columbia.edu/~julia/). Recently, I researched the use of large language models for the study of negotiation at the University of Southern California's [Affective Computing Lab](https://emotions.ict.usc.edu/), where I was advised by Professor [Jonathan Gratch](https://people.ict.usc.edu/~gratch/). Previously, working with Professor [Vicente Ordóñez-Román](https://www.cs.rice.edu/~vo9/) in the [Vision, Language, and Learning Lab](https://vislang.ai/) at Rice University, I investigated the relationship between images' visual complexity and image descriptions' linguistic complexity. Working with [Dr. Kate Moore](https://www.linkedin.com/in/kate-moore-644aab9) in the [Corter Lab](https://www.tc.columbia.edu/faculty/jec34/) at Columbia's Teachers College, I have also researched communication patterns in collaborative learning. I am primarily interested in natural language processing.

* TOC
{:toc}

## Publications
<div class="blog-post subtext p-2">
	<ul class="list-unstyled">
		<li class="media">
			<img class="mr-3 img-thumbnail" src="images/llm_nego.png" width="100" alt="">
			<div class="media-body">
			<p class="my-auto">
			<a class="blue_link" href="https://doi.org/10.1145/3565287.3617637">
				Toward a Better Understanding of the Emotional Dynamics of Negotiation with Large Language Models
			</a> 
			<span class="pub_authors d-lg-block">
				<b>Eleanor Lin</b>, James Hale, and Jonathan Gratch
			</span>
			<span class="pub_info d-inline">
				 In <i>The Twenty-fourth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (MobiHoc ’23), October 23–26, 2023, Washington, DC, USA.</i> ACM, New York, NY, USA, 6 pages. 
			</span>
			[<a href="https://doi.org/10.1145/3565287.3617637">Paper</a>] 
			[<a href="files/nego_slides.pdf">Slides</a>] 
			[<a href="files/nego_poster.pdf">Poster</a>] 
			</p>
			</div>
		</li>
	</ul>
</div><!-- /.blog-post -->

## Presentations
<div class="blog-post subtext p-2">
	<ul class="list-unstyled">
		<li class="media">
			<img class="mr-3 img-thumbnail" src="images/complex_noncomplex1024_1.jpg" width="100" alt="">
			<div class="media-body">
			<p class="my-auto">
			<a class="blue_link" href="files/dreu_report.pdf">
				Text-Based Prediction of Visual Complexity: How Does What We See Influence What We Say?
			</a> 
			<span class="pub_authors d-lg-block">
				<b>Lin, E.</b>, Yang, Z., & Ordóñez, V.
			</span>
			<span class="pub_info d-inline">
				Columbia University Undergraduate Research Symposium, New York, NY, October 2022. 
			</span>
			[<a href="files/dreu_report.pdf">Report</a>] 
			[<a href="files/dreu_slides.pdf">Slides</a>] 
			[<a href="files/poster_visual_complexity_lin_2022.pdf">Poster</a>] 
			</p>
			</div>
		</li>
	</ul>
</div><!-- /.blog-post -->

## Research Experience

## Teaching Experience

## Work Experience

<div style="text-align: right"> Website design inspired by <a href="https://jr4fs.github.io/">jr4fs.github.io</a>.</div>
<br />
<br />
